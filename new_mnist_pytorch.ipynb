{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "RSDGF-1m3lNY"
      },
      "outputs": [],
      "source": [
        "# 새로 짠 코드\n",
        "\n",
        "# import\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# gpu 사용\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 정규화에 쓰일 파라미터 정의 (평균, 분산)\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "train_dataset = datasets.MNIST('./data', train=True, download=True,\n",
        "                               transform=transform)\n",
        "test_dataset = datasets.MNIST('./data', train=False, download=True,\n",
        "                              transform=transform)\n",
        "\n",
        "# batch_size는 64로 설정하고 데이터 로더를 사용\n",
        "batch_size = 64\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LXBvVYEK3wEV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 모델정의\n",
        "class LogisticRegression(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        output = self.linear(x)\n",
        "        return output\n",
        "\n"
      ],
      "metadata": {
        "id": "PD28z8BKmPKI"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정의\n",
        "lr = 0.01\n",
        "input_dim = 784\n",
        "output_dim = 10\n",
        "model = LogisticRegression(input_dim,output_dim).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n"
      ],
      "metadata": {
        "id": "jn-lIzhPmUoz"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # forward\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # backward & 갱신\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # 출력\n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                   .format(epoch+1, num_epochs, i+1, len(train_loader), loss.item()))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3C42afcVmXoG",
        "outputId": "493854c7-45c3-4752-f719-aab9299c0705"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [100/938], Loss: 0.5856\n",
            "Epoch [1/10], Step [200/938], Loss: 0.3794\n",
            "Epoch [1/10], Step [300/938], Loss: 0.4731\n",
            "Epoch [1/10], Step [400/938], Loss: 0.3762\n",
            "Epoch [1/10], Step [500/938], Loss: 0.2879\n",
            "Epoch [1/10], Step [600/938], Loss: 0.3710\n",
            "Epoch [1/10], Step [700/938], Loss: 0.3607\n",
            "Epoch [1/10], Step [800/938], Loss: 0.3182\n",
            "Epoch [1/10], Step [900/938], Loss: 0.3902\n",
            "Epoch [2/10], Step [100/938], Loss: 0.1956\n",
            "Epoch [2/10], Step [200/938], Loss: 0.2843\n",
            "Epoch [2/10], Step [300/938], Loss: 0.3090\n",
            "Epoch [2/10], Step [400/938], Loss: 0.2990\n",
            "Epoch [2/10], Step [500/938], Loss: 0.2333\n",
            "Epoch [2/10], Step [600/938], Loss: 0.2006\n",
            "Epoch [2/10], Step [700/938], Loss: 0.4115\n",
            "Epoch [2/10], Step [800/938], Loss: 0.2633\n",
            "Epoch [2/10], Step [900/938], Loss: 0.3118\n",
            "Epoch [3/10], Step [100/938], Loss: 0.5336\n",
            "Epoch [3/10], Step [200/938], Loss: 0.2954\n",
            "Epoch [3/10], Step [300/938], Loss: 0.2669\n",
            "Epoch [3/10], Step [400/938], Loss: 0.3195\n",
            "Epoch [3/10], Step [500/938], Loss: 0.3621\n",
            "Epoch [3/10], Step [600/938], Loss: 0.2036\n",
            "Epoch [3/10], Step [700/938], Loss: 0.3082\n",
            "Epoch [3/10], Step [800/938], Loss: 0.2205\n",
            "Epoch [3/10], Step [900/938], Loss: 0.3408\n",
            "Epoch [4/10], Step [100/938], Loss: 0.2128\n",
            "Epoch [4/10], Step [200/938], Loss: 0.3266\n",
            "Epoch [4/10], Step [300/938], Loss: 0.3689\n",
            "Epoch [4/10], Step [400/938], Loss: 0.5661\n",
            "Epoch [4/10], Step [500/938], Loss: 0.1749\n",
            "Epoch [4/10], Step [600/938], Loss: 0.6784\n",
            "Epoch [4/10], Step [700/938], Loss: 0.1372\n",
            "Epoch [4/10], Step [800/938], Loss: 0.3587\n",
            "Epoch [4/10], Step [900/938], Loss: 0.3781\n",
            "Epoch [5/10], Step [100/938], Loss: 0.3660\n",
            "Epoch [5/10], Step [200/938], Loss: 0.2748\n",
            "Epoch [5/10], Step [300/938], Loss: 0.3817\n",
            "Epoch [5/10], Step [400/938], Loss: 0.1798\n",
            "Epoch [5/10], Step [500/938], Loss: 0.2157\n",
            "Epoch [5/10], Step [600/938], Loss: 0.1720\n",
            "Epoch [5/10], Step [700/938], Loss: 0.1197\n",
            "Epoch [5/10], Step [800/938], Loss: 0.3392\n",
            "Epoch [5/10], Step [900/938], Loss: 0.4377\n",
            "Epoch [6/10], Step [100/938], Loss: 0.1939\n",
            "Epoch [6/10], Step [200/938], Loss: 0.3166\n",
            "Epoch [6/10], Step [300/938], Loss: 0.2720\n",
            "Epoch [6/10], Step [400/938], Loss: 0.1864\n",
            "Epoch [6/10], Step [500/938], Loss: 0.5075\n",
            "Epoch [6/10], Step [600/938], Loss: 0.3129\n",
            "Epoch [6/10], Step [700/938], Loss: 0.1624\n",
            "Epoch [6/10], Step [800/938], Loss: 0.2795\n",
            "Epoch [6/10], Step [900/938], Loss: 0.4092\n",
            "Epoch [7/10], Step [100/938], Loss: 0.4578\n",
            "Epoch [7/10], Step [200/938], Loss: 0.5078\n",
            "Epoch [7/10], Step [300/938], Loss: 0.2121\n",
            "Epoch [7/10], Step [400/938], Loss: 0.4601\n",
            "Epoch [7/10], Step [500/938], Loss: 0.2727\n",
            "Epoch [7/10], Step [600/938], Loss: 0.3827\n",
            "Epoch [7/10], Step [700/938], Loss: 0.2548\n",
            "Epoch [7/10], Step [800/938], Loss: 0.2602\n",
            "Epoch [7/10], Step [900/938], Loss: 0.3717\n",
            "Epoch [8/10], Step [100/938], Loss: 0.2336\n",
            "Epoch [8/10], Step [200/938], Loss: 0.2917\n",
            "Epoch [8/10], Step [300/938], Loss: 0.1912\n",
            "Epoch [8/10], Step [400/938], Loss: 0.3430\n",
            "Epoch [8/10], Step [500/938], Loss: 0.3406\n",
            "Epoch [8/10], Step [600/938], Loss: 0.4095\n",
            "Epoch [8/10], Step [700/938], Loss: 0.2346\n",
            "Epoch [8/10], Step [800/938], Loss: 0.2560\n",
            "Epoch [8/10], Step [900/938], Loss: 0.1575\n",
            "Epoch [9/10], Step [100/938], Loss: 0.3300\n",
            "Epoch [9/10], Step [200/938], Loss: 0.1875\n",
            "Epoch [9/10], Step [300/938], Loss: 0.2424\n",
            "Epoch [9/10], Step [400/938], Loss: 0.2786\n",
            "Epoch [9/10], Step [500/938], Loss: 0.1927\n",
            "Epoch [9/10], Step [600/938], Loss: 0.1817\n",
            "Epoch [9/10], Step [700/938], Loss: 0.2638\n",
            "Epoch [9/10], Step [800/938], Loss: 0.1970\n",
            "Epoch [9/10], Step [900/938], Loss: 0.1689\n",
            "Epoch [10/10], Step [100/938], Loss: 0.2159\n",
            "Epoch [10/10], Step [200/938], Loss: 0.4659\n",
            "Epoch [10/10], Step [300/938], Loss: 0.2834\n",
            "Epoch [10/10], Step [400/938], Loss: 0.2463\n",
            "Epoch [10/10], Step [500/938], Loss: 0.2499\n",
            "Epoch [10/10], Step [600/938], Loss: 0.3849\n",
            "Epoch [10/10], Step [700/938], Loss: 0.2554\n",
            "Epoch [10/10], Step [800/938], Loss: 0.2206\n",
            "Epoch [10/10], Step [900/938], Loss: 0.1969\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('정확도: {} %'.format(100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tohG41lmZXZ",
        "outputId": "38ee5c65-ed1a-462b-ffae-91656ff92971"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 92.24 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hkmaw-vrn3K8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}